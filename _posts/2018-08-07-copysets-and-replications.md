---
layout: post
title: Copyset与多副本
categories: [distributed-programming]
description: distributed-programming
keywords: distributed-programming
---

随机分布副本的方式被广泛引用到分布式领域。但是，随着集群规模的扩大，数据丢失的可能性直线上升。

通常情况下，分布式系统就会将自身服务进行分片，每个分片又会包含固定的副本数，然后将每个分片的副本随机分布在集群内。这里我们拿副本数为3的情况举例。每个分片会分布在不同的机器上，比如$$\{1,2,3\}$$、$$\{4,5,6\}$$，随着分片的增多，这样的服务器排列组合也会随之增加。那么如果集群内任意挂掉3台服务器，那么导致任一分片的全部副本都损失的概率也随之增加。比如，最极端的例子，只要我们的副本使用的服务器的排列组合足够多，满足了任意3台服务器的全排列，则，集群内任意挂掉3台服务器时，必定会有一个分片的数据全部丢失。这个趋势，facebook的论文[^1]中给出模拟图：

![](/images/posts/distribution/copysets-0.png)

在以往的算法下，为了减少数据丢失的可能性，只能提升副本数，但是这样会带来成本的上升。
![](/images/posts/distribution/copysets-1.png)

为了优化减少数据丢失的可能性，facebook提出了一种新的副本分布方式[^1]，其将节点先划分为`copyset`。

为了解释论证，论文中首先提出了一个概念`scatter width`$$S$$，$$S$$为在副本放置的组合中，任一节点与多少个其他节点由数据通信。比如我们的几个副本组合为$$\{1,2,3\}$$，$$\{4,5,6\}$$，$$\{7,8,9\}$$，$$\{1,4,7\}$$，$$\{2,5,8\}$$，$$\{3,6,9\}$$，则$$S = 4$$，因为其中任一节点与其余4个节点由数据同步。比如6这个节点，它分别跟4,5,3,9同步数据。我们将一个分片的副本组合称为一个`copyset`，例如$$\{1,2,3\}$$为一个`copyset`。

* 如果副本分布的$$S$$太小，则故障恢复速度会慢，比如$$S$$为2，那个故障恢复时，只能从2个节点上恢复数据。
* 如果$$S$$太大，则会增加数据丢失的风险。因为当任意节点故障时，其波及的分片数随$$S$$的增大而增多。

故，论文中提出了4个核心变量：

* $$S$$
* $$R$$ 副本数
* $$N$$ 集群实例数
* $$P$$ 副本排列组合次数

比如，我们有9个节点，当$$R = 3$$时，我们排列一次得，可选的副本分布为：$$\{1,2,3\}$$，$$\{4,5,6\}$$，$$\{7,8,9\}$$，如果对应的分片数不够，则我们需要再排列一次，得到更多的副本组合，比如：$$\{1,4,7\}$$，$$\{2,5,8\}$$，$$\{3,6,9\}$$。

因此可得，$$ S = P(R-1) $$，`copyset`数为$$P\frac{N}{R}$$，将$$S$$带入得$$\frac{S}{R-1} \cdot \frac{N}{R}$$。

论文中讲述，为了降低数据的丢失概率，排布数据副本时，追求更低的$$S$$。因为在实际情况中，故障恢复的瓶颈通常是服务器带宽，而不是$$S$$。



静态分配节点到copyset中，随机选取一个节点作为主节点

论文中使用`copyset`算法后与之前的对比：
![](/images/posts/distribution/copysets-2.png)

* [^1]: [Copysets: Reducing the Frequency of Data Loss in Cloud Storage](/images/posts/distribution/Copysets-Reducing-the-Frequency-of-Data-Loss-in-Cloud-Storage.pdf)
* [^2]: [Copysets and Chainsets: A Better Way to Replicate](http://hackingdistributed.com/2014/02/14/chainsets/)
